# Revisiting Text-Based Person Retrieval: Mitigating Annotation-Induced Mispredictions with Multimodal Large Language Models
This repository provides improved test sets for three mainstream Text-Based Person Retrieval (TBPR) benchmarks: **CUHK-PEDES**, **RSTPReid**, and **ICFG-PEDES**. These datasets are refined using our optimal caption annotation rewriting method, as proposed in the paper:

> **Revisiting Text-Based Person Retrieval: Mitigating Annotation-Induced Mismatches with Multimodal Large Language Models**  
> Zihang Han, Chao Zhu, Mengyin Liu, Xu-Cheng Yin

# Overview
<img width="1262" height="800" alt="fig0" src="https://github.com/user-attachments/assets/2979d079-d190-48b4-8ada-607bebb471af" />

Text-Based Person Retrieval (TBPR) datasets often suffer from annotation-induced mismatches, where multiple images with different IDs share highly similar or identical textual descriptions. Our work addresses this issue by leveraging multimodal large language models (MLLMs) to generate more distinctive and discriminative captions for each image, reducing evaluation bias and improving retrieval accuracy.

This repository contains the **refined test sets** for:

- [CUHK-PEDES](https://github.com/ShuangLI59/Person-Search-with-Natural-Language-Description)
- [RSTPReid](https://github.com/NjtechCVLab/RSTPReid-Dataset)
- [ICFG-PEDES](https://github.com/zifyloo/SSAN)

# Dataset Structure

Each dataset folder contains:
- The refined captions generated by our optimal method (Separate Expansion Followed By Merging)
- The refined_test_captions.json file for ICFG-PEDES will be uploaded soon.

**Example directory structure:**
```
Revisiting-Text-Based-Person-Retrieval/  
├── CUHK-PEDES/  
│ └── refined_test_captions.json  
├── RSTPReid/  
│ └── refined_test_captions.json  
├── ICFG-PEDES/  
│ └── refined_test_captions.json  
└── README.md
```

# Download
**Baidu Netdisk**  
Link: https://pan.baidu.com/s/1LQr4RQ6kO8-s8h0rG5GS2A?pwd=ahyj  
Password: ahyj

# Data Format

- Each `.json` file  defined by the original dataset, where each entry includes an image ID and its corresponding refined textual description.

# Usage

1. Download and extract the refined captions for the dataset you are using.
2. Replace the original test set captions with the provided refined captions in your TBPR evaluation pipeline.
3. Evaluate your model as usual.
> **Note:** Please ensure you have access to the original datasets, as only the **refined annotations** for the test sets are provided here.

# Citation

If you use these refined test sets in your research, please cite our paper:

```bibtex
@article{han2025revisiting,
  title={Revisiting Text-Based Person Retrieval: Mitigating Annotation-Induced Mismatches with Multimodal Large Language Models},
  author={Han, Zihang and Zhu, Chao and Liu, Mengyin and Yin, Xu-Cheng},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  year={2025}
}
```

# Contact
For questions or feedback, please contact:

Zihang Han: zihanghan@xs.ustb.edu.cn
Chao Zhu: chaozhu@ustb.edu.cn

# Acknowledgements
Original datasets: CUHK-PEDES, RSTPReid, ICFG-PEDES
